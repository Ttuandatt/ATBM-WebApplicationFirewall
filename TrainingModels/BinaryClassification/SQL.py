#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
train_sql_models.py

Cháº¡y training/evaluation cho SQLi dataset (CountVectorizer + nhiá»u classifier).
LÆ°u NB model vÃ  vectorizer ra disk, vÃ  káº¿t quáº£ training ra file CSV.

Usage:
    python train_sql_models.py
"""

import os
import sys
import joblib
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

# classifiers
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, StackingClassifier


# =====================================================
# ğŸ”¹ CÃ¡c hÃ m tiá»‡n Ã­ch
# =====================================================

def find_dataset():
    """Tá»± tÃ¬m file dataset Ä‘Ã£ xá»­ lÃ½."""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    candidates = [
        os.path.join(script_dir, 'data', 'processed', 'processed_payloads.csv'),
        os.path.join(script_dir, '..', 'data', 'processed', 'processed_payloads.csv'),
        os.path.join(script_dir, '..', '..', 'data', 'processed', 'processed_payloads.csv'),
    ]
    for p in candidates:
        if os.path.exists(p):
            return os.path.abspath(p)
    raise FileNotFoundError("KhÃ´ng tÃ¬m tháº¥y dataset. ÄÃ£ thá»­:\n" + "\n".join(candidates))


def custom_tokenizer(text):
    return text.split()

def ensure_dir(path):
    """Äáº£m báº£o thÆ° má»¥c tá»“n táº¡i."""
    d = os.path.dirname(path)
    if d and not os.path.exists(d):
        os.makedirs(d, exist_ok=True)


# =====================================================
# ğŸ”¹ Quáº£n lÃ½ lÆ°u káº¿t quáº£ vÃ  report
# =====================================================

def load_previous_results(results_path):
    """Äá»c káº¿t quáº£ cÅ© (náº¿u cÃ³)."""
    if os.path.exists(results_path):
        return pd.read_csv(results_path)
    else:
        return pd.DataFrame(columns=["model", "accuracy", "report_file", "model_file"])


def save_result(results_path, model_name, accuracy, report_text, model_file):
    """Ghi káº¿t quáº£ má»›i vÃ o CSV vÃ  lÆ°u report ra file riÃªng."""
    ensure_dir(results_path)
    base_dir = os.path.dirname(results_path)

    # LÆ°u file report chi tiáº¿t
    report_path = os.path.join(base_dir, f"{model_name}_report.txt")
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(report_text)

    # Ghi summary vÃ o CSV
    df = load_previous_results(results_path)
    new_row = pd.DataFrame([{
        "model": model_name,
        "accuracy": accuracy,
        "report_file": report_path,
        "model_file": model_file
    }])
    df = pd.concat([df, new_row], ignore_index=True)
    df.to_csv(results_path, index=False)
    print(f"âœ… ÄÃ£ lÆ°u káº¿t quáº£ cá»§a {model_name} vÃ o {results_path}")


def model_already_trained(results_df, model_name):
    """Kiá»ƒm tra mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c train chÆ°a."""
    return model_name in results_df["model"].values


# =====================================================
# ğŸ”¹ HÃ m chÃ­nh
# =====================================================

def main():
    print("ğŸ” Äang tÃ¬m dataset...")
    try:
        df_path = find_dataset()
    except FileNotFoundError as ex:
        print("ERROR:", ex)
        sys.exit(1)

    print("ğŸ“‚ Äang load dataset tá»«:", df_path)
    df = pd.read_csv(df_path, dtype=str, keep_default_na=False)

    # Chuáº©n hÃ³a cá»™t
    cols = [c.lower() for c in df.columns]
    payload_col = df.columns[cols.index('payload')] if 'payload' in cols else df.columns[0]
    label_col = df.columns[cols.index('is_malicious')] if 'is_malicious' in cols else df.columns[1]

    df = df[[payload_col, label_col]].copy()
    df.columns = ['payload', 'is_malicious']

    # Chuyá»ƒn nhÃ£n thÃ nh sá»‘
    def to_int_lbl(x):
        try:
            return int(float(x))
        except Exception:
            return 1 if str(x).strip() else 0

    df['payload'] = df['payload'].astype(str).fillna('').apply(lambda s: s.strip())
    df['is_malicious'] = df['is_malicious'].apply(to_int_lbl).astype(int)
    df = df[df['payload'] != ''].drop_duplicates(subset=['payload'])
    df = df[df['is_malicious'].isin([0, 1])]

    print("ğŸ“Š Dataset:", len(df), "máº«u.")
    print(df['is_malicious'].value_counts())

    # Vector hÃ³a
    vectorizer = CountVectorizer(min_df=1, tokenizer=custom_tokenizer, ngram_range=(1, 3))
    X = vectorizer.fit_transform(df['payload'])
    y = df['is_malicious'].values
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

    # ThÆ° má»¥c lÆ°u model + káº¿t quáº£
    script_dir = os.path.dirname(os.path.abspath(__file__))
    save_dir = os.path.join(script_dir, "saved_models")
    results_path = os.path.join(save_dir, "results.csv")
    os.makedirs(save_dir, exist_ok=True)

    results_df = load_previous_results(results_path)

    # =====================================================
    # ğŸ”¸ Danh sÃ¡ch mÃ´ hÃ¬nh cáº§n train
    # =====================================================
    models = [
        ("NaiveBayes", MultinomialNB()),
        ("SVM", SVC()),
        ("LogisticRegression", LogisticRegression(max_iter=2000)),
        ("DecisionTree", DecisionTreeClassifier()),
        ("Bagging", BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)),
        ("AdaBoost", AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1), n_estimators=30, random_state=42))
        # ("RandomForest", RandomForestClassifier(n_estimators=100, random_state=42)),
        # ("Stacking", StackingClassifier(
        #     estimators=[
        #         ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),
        #         ('svc', SVC(probability=True, random_state=42))
        #     ],
        #     final_estimator=LogisticRegression(),
        #     n_jobs=-1
        # ))
    ]

    # =====================================================
    # ğŸ”¸ Train tá»«ng mÃ´ hÃ¬nh (chá»‰ train náº¿u chÆ°a cÃ³ káº¿t quáº£)
    # =====================================================
    best_model_name = None
    best_acc = 0
    best_model = None

    for model_name, clf in models:
        if model_already_trained(results_df, model_name):
            print(f"â© Bá» qua {model_name} (Ä‘Ã£ cÃ³ trong káº¿t quáº£ trÆ°á»›c Ä‘Ã³).")
            continue

        print(f"\nğŸš€ Training {model_name}...")
        clf.fit(X_train, y_train)
        y_pred = clf.predict(X_test)

        acc = accuracy_score(y_test, y_pred)
        report = classification_report(y_test, y_pred)

        print(f"{model_name} Accuracy: {acc:.4f}")
        print(report)

        # LÆ°u model táº¡m thá»i
        model_path = os.path.join(save_dir, f"{model_name}.pkl")
        joblib.dump(clf, model_path)

        # Ghi káº¿t quáº£
        save_result(results_path, model_name, acc, report, model_path)

        # Cáº­p nháº­t model tá»‘t nháº¥t
        if acc > best_acc:
            best_acc = acc
            best_model_name = model_name
            best_model = clf

    # =====================================================
    # ğŸ”¸ Náº¿u khÃ´ng cÃ³ model má»›i nÃ o Ä‘Æ°á»£c train, chá»n tá»« file results.csv
    # =====================================================
    if best_model is None:
        print("âš ï¸ KhÃ´ng cÃ³ model nÃ o Ä‘Æ°á»£c train má»›i. Äang chá»n model tá»‘t nháº¥t tá»« káº¿t quáº£ trÆ°á»›c Ä‘Ã³...")

        if os.path.exists(results_path):
            df_results = pd.read_csv(results_path)
            if not df_results.empty:
                # Ã‰p kiá»ƒu cá»™t accuracy sang float Ä‘á»ƒ so sÃ¡nh
                df_results["accuracy"] = pd.to_numeric(df_results["accuracy"], errors="coerce")
                best_row = df_results.loc[df_results["accuracy"].idxmax()]
                best_model_name = best_row["model"]
                best_acc = best_row["accuracy"]
                best_model_path = best_row["model_file"]

                print(f"âœ… Model tá»‘t nháº¥t trÆ°á»›c Ä‘Ã³: {best_model_name} (accuracy={best_acc:.4f})")
                # Load láº¡i model tá»‘t nháº¥t tá»« file .pkl
                best_model = joblib.load(best_model_path)
            else:
                print("âš ï¸ File results.csv rá»—ng â€” khÃ´ng cÃ³ model nÃ o Ä‘á»ƒ chá»n.")
        else:
            print("âš ï¸ ChÆ°a cÃ³ file results.csv Ä‘á»ƒ Ä‘á»c káº¿t quáº£ trÆ°á»›c Ä‘Ã³.")

    # =====================================================
    # ğŸ”¸ LÆ°u model vÃ  vectorizer chuáº©n cho Flask sá»­ dá»¥ng
    # =====================================================
    if best_model is not None:
        sqli_model_path = os.path.join(save_dir, "sqli.pkl")
        joblib.dump(best_model, sqli_model_path)
        print(f"ğŸ’¾ ÄÃ£ lÆ°u model tá»‘t nháº¥t ({best_model_name}) -> {sqli_model_path}")
    else:
        print("âŒ KhÃ´ng thá»ƒ táº¡o sqli.pkl vÃ¬ khÃ´ng tÃ¬m tháº¥y model nÃ o há»£p lá»‡.")

    # LÆ°u vectorizer (luÃ´n cáº­p nháº­t)
    vectorizer_path = os.path.join(save_dir, "vectorizer.pkl")
    joblib.dump(vectorizer, vectorizer_path)
    print(f"ğŸ’¾ ÄÃ£ lÆ°u vectorizer -> {vectorizer_path}")

    print("\nğŸ¯ HoÃ n táº¥t training táº¥t cáº£ mÃ´ hÃ¬nh!")


if __name__ == "__main__":
    main()
