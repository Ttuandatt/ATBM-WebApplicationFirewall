22/10/2025 (tuandat):
- Kh√°c bi·ªát gi·ªØa "deny" v√† "drop" trong firewall logs:
    + "deny": G√≥i tin b·ªã t·ª´ ch·ªëi v√† g·ª≠i th√¥ng b√°o v·ªÅ ngu·ªìn g·ªëc.
    + "drop": G√≥i tin b·ªã lo·∫°i b·ªè m√† kh√¥ng g·ª≠i th√¥ng b√°o n√†o.
- C·ª• th·ªÉ h∆°n:
"Firewall Deny" v√† "Firewall Drop" m√¥ t·∫£ hai c√°ch kh√°c nhau m√† t∆∞·ªùng l·ª≠a x·ª≠ l√Ω c√°c g√≥i tin kh·ªõp v·ªõi quy t·∫Øc t·ª´ ch·ªëi l∆∞u l∆∞·ª£ng. S·ª± kh√°c bi·ªát n√†y ·∫£nh h∆∞·ªüng ƒë·∫øn c√°ch ng∆∞·ªùi g·ª≠i ƒë∆∞·ª£c th√¥ng b√°o, h√†nh vi k·∫øt n·ªëi, ghi nh·∫≠t k√Ω v√† t∆∞∆°ng t√°c t∆∞·ªùng l·ª≠a c√≥ tr·∫°ng th√°i.

S·ª± kh√°c bi·ªát c·ªët l√µi

Ph·∫£n h·ªìi cho ng∆∞·ªùi g·ª≠i
T·ª´ ch·ªëi: ch·ªß ƒë·ªông t·ª´ ch·ªëi g√≥i tin v√† tr·∫£ v·ªÅ m·ªôt g√≥i tin l·ªói cho ng∆∞·ªùi g·ª≠i (th∆∞·ªùng l√† m·ªôt g√≥i tin ICMP kh√¥ng th·ªÉ truy c·∫≠p ƒë∆∞·ª£c ƒë·ªëi v·ªõi IP/UDP ho·∫∑c m·ªôt g√≥i tin TCP RST ƒë·ªëi v·ªõi TCP). Ng∆∞·ªùi g·ª≠i ngay l·∫≠p t·ª©c bi·∫øt r·∫±ng g√≥i tin ƒë√£ b·ªã t·ª´ ch·ªëi.
Drop: √¢m th·∫ßm lo·∫°i b·ªè g√≥i tin; kh√¥ng c√≥ ph·∫£n h·ªìi n√†o ƒë∆∞·ª£c g·ª≠i ƒëi. Ng∆∞·ªùi g·ª≠i ch·ªâ th·∫•y thi·∫øu ph·∫£n h·ªìi, c√≥ th·ªÉ tr√¥ng gi·ªëng nh∆∞ m·∫•t g√≥i tin ho·∫∑c t∆∞·ªùng l·ª≠a c·ªë t√¨nh ·∫©n m√¨nh.
T√°c ƒë·ªông ƒë·∫øn h√†nh vi k·∫øt n·ªëi
T·ª´ ch·ªëi: ch·∫•m d·ª©t ho·∫∑c ngƒÉn ch·∫∑n k·∫øt n·ªëi nhanh ch√≥ng v√¨ th√¥ng b√°o t·ª´ ch·ªëi th√¥ng b√°o cho c√°c ƒëi·ªÉm cu·ªëi d·ª´ng th·ª≠ l·∫°i ho·∫∑c ƒë√≥ng c√°c n·ªó l·ª±c.
B·ªè qua: ng∆∞·ªùi g·ª≠i c√≥ th·ªÉ ti·∫øp t·ª•c truy·ªÅn l·∫°i (th·ª≠ l·∫°i TCP) ho·∫∑c ƒë·ª£i cho ƒë·∫øn khi h·∫øt th·ªùi gian; n·ªó l·ª±c k·∫øt n·ªëi b·ªã treo ho·∫∑c ch·∫≠m.
C√°c tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng v√† m·ª•c ƒë√≠ch
T·ª´ ch·ªëi: ƒë∆∞·ª£c s·ª≠ d·ª•ng khi b·∫°n mu·ªën l·ªói nhanh, ph·∫£n h·ªìi ch·∫©n ƒëo√°n t·ªët h∆°n ho·∫∑c ƒë·ªÉ b√°o hi·ªáu r√µ r√†ng r·∫±ng l∆∞u l∆∞·ª£ng kh√¥ng ƒë∆∞·ª£c ph√©p (h·ªØu √≠ch cho c√°c m√°y kh√°ch h·ª£p ph√°p v√† x·ª≠ l√Ω s·ª± c·ªë).
Drop: ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t√†ng h√¨nh/·∫©n (l√†m cho c√°c d·ªãch v·ª• c√≥ v·∫ª kh√¥ng th·ªÉ truy c·∫≠p ƒë∆∞·ª£c), l√†m ch·∫≠m k·∫ª t·∫•n c√¥ng b·∫±ng c√°ch g√¢y ra th·ªùi gian ch·ªù ho·∫∑c ƒë·ªÉ tr√°nh ti·∫øt l·ªô s·ª± hi·ªán di·ªán c·ªßa t∆∞·ªùng l·ª≠a ho·∫∑c c·∫•u tr√∫c m·∫°ng.
S·ª± ƒë√°nh ƒë·ªïi v·ªÅ an ninh/ho·∫°t ƒë·ªông
T·ª´ ch·ªëi:
∆Øu ƒëi·ªÉm: chuy·ªÉn ƒë·ªïi d·ª± ph√≤ng nhanh h∆°n, x·ª≠ l√Ω s·ª± c·ªë t·ªët h∆°n, gi·∫£m s·ªë l·∫ßn th·ª≠ l·∫°i v√† t·∫£i kh√¥ng c·∫ßn thi·∫øt.
Nh∆∞·ª£c ƒëi·ªÉm: cung c·∫•p th√¥ng tin cho k·∫ª t·∫•n c√¥ng (ti·∫øt l·ªô m√°y ch·ªß t·ªìn t·∫°i v√† ƒëang ch·ªß ƒë·ªông t·ª´ ch·ªëi).
L√†m r∆°i:
∆Øu ƒëi·ªÉm: t√†ng h√¨nh h∆°n, c√≥ th·ªÉ ngƒÉn ch·∫∑n m√°y qu√©t v√† c√°c cu·ªôc t·∫•n c√¥ng t·ª± ƒë·ªông.
Nh∆∞·ª£c ƒëi·ªÉm: l√£ng ph√≠ th·ªùi gian th·ª≠ l·∫°i/h·∫øt th·ªùi gian ch·ªù c·ªßa m√°y kh√°ch, kh√≥ kh·∫Øc ph·ª•c s·ª± c·ªë, c√≥ th·ªÉ g√¢y ra t√°c d·ª•ng ph·ª• cho c√°c d·ªãch v·ª• h·ª£p ph√°p (treo l√¢u).
Ghi nh·∫≠t k√Ω v√† gi√°m s√°t
C·∫£ hai ƒë·ªÅu c√≥ th·ªÉ ƒë∆∞·ª£c ghi l·∫°i, nh∆∞ng h√†nh vi ghi l·∫°i th·ª±c t·∫ø s·∫Ω kh√°c nhau:
T·ª´ ch·ªëi: nh·∫≠t k√Ω c√πng v·ªõi ph·∫£n h·ªìi t·ª´ ch·ªëi r√µ r√†ng cung c·∫•p b·∫±ng ch·ª©ng r√µ r√†ng h∆°n v·ªÅ c√°c s·ª± ki·ªán t·ª´ ch·ªëi.
B·ªè qua: nh·∫≠t k√Ω r·∫•t c·∫ßn thi·∫øt ƒë·ªÉ hi·ªÉn th·ªã; n·∫øu kh√¥ng ghi nh·∫≠t k√Ω, c√°c g√≥i tin b·ªã b·ªè qua s·∫Ω kh√¥ng hi·ªÉn th·ªã v√† c√≥ th·ªÉ l√†m ph·ª©c t·∫°p qu√° tr√¨nh ·ª©ng ph√≥ s·ª± c·ªë.
T∆∞·ªùng l·ª≠a c√≥ tr·∫°ng th√°i so v·ªõi t∆∞·ªùng l·ª≠a kh√¥ng tr·∫°ng th√°i
Thi·∫øt b·ªã c√≥ tr·∫°ng th√°i th∆∞·ªùng theo d√µi tr·∫°ng th√°i k·∫øt n·ªëi v√† h√†nh ƒë·ªông "t·ª´ ch·ªëi" hay "h·ªßy" c·ªßa n√≥ c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn vi·ªác n√≥ c√≥ g·ª≠i reset/ICMP hay kh√¥ng v√† c√°ch n√≥ x√≥a tr·∫°ng th√°i.
B·ªô l·ªçc kh√¥ng tr·∫°ng th√°i ch·ªâ √°p d·ª•ng quy·∫øt ƒë·ªãnh ƒë√£ c·∫•u h√¨nh cho m·ªói g√≥i tin.
V√≠ d·ª• v√† h√†nh vi ƒëi·ªÉn h√¨nh

C·ªïng TCP b·ªã ch·∫∑n b·∫±ng T·ª´ ch·ªëi: m√°y kh√°ch nh·∫≠n ƒë∆∞·ª£c TCP RST ‚Üí k·∫øt n·ªëi b·ªã l·ªói ngay l·∫≠p t·ª©c.
C·ªïng TCP b·ªã ch·∫∑n v·ªõi Drop: m√°y kh√°ch th·∫•y th·ªùi gian ch·ªù SYN, nhi·ªÅu l·∫ßn truy·ªÅn l·∫°i, cu·ªëi c√πng l√† th·ªùi gian ch·ªù.
D·ªãch v·ª• UDP b·ªã h·ªßy: m√°y kh√°ch kh√¥ng nh·∫≠n ƒë∆∞·ª£c ICMP kh√¥ng th·ªÉ truy c·∫≠p ‚Üí xu·∫•t hi·ªán d∆∞·ªõi d·∫°ng m·∫•t g√≥i tin.
G·ª≠i ICMP kh√¥ng th·ªÉ truy c·∫≠p v·ªõi T·ª´ ch·ªëi c√≥ th·ªÉ ƒë∆∞a ra ch·∫©n ƒëo√°n nhanh h∆°n (tr·∫£ l·ªùi ping v·ªõi ƒë√≠ch kh√¥ng th·ªÉ truy c·∫≠p so v·ªõi im l·∫∑ng).
Khi n√†o n√™n ch·ªçn c√°i n√†o

S·ª≠ d·ª•ng T·ª´ ch·ªëi khi: h·ªó tr·ª£ kh√°ch h√†ng h·ª£p ph√°p, gi·∫£m s·ªë l·∫ßn th·ª≠ l·∫°i, gi√∫p kh·∫Øc ph·ª•c s·ª± c·ªë d·ªÖ d√†ng h∆°n v√† khi vi·ªác t·ª´ ch·ªëi ƒë∆∞·ª£c ch·∫•p nh·∫≠n.
S·ª≠ d·ª•ng Drop khi: gi·∫£m thi·ªÉu r√≤ r·ªâ th√¥ng tin, ngƒÉn ch·∫∑n ho·∫°t ƒë·ªông do th√°m ho·∫∑c th·ª±c hi·ªán t∆∞ th·∫ø ·∫©n n√°u m·∫∑c ƒë·ªãnh.
Ghi ch√∫ th·ª±c hi·ªán

Thu·∫≠t ng·ªØ c√≥ th·ªÉ kh√°c nhau: m·ªôt s·ªë nh√† cung c·∫•p g·ªçi "t·ª´ ch·ªëi" trong khi nh·ªØng nh√† cung c·∫•p kh√°c g·ªçi l√† "t·ª´ ch·ªëi"; x√°c nh·∫≠n t√†i li·ªáu c·ªßa nh√† cung c·∫•p. ƒêi·ªÅu quan tr·ªçng l√† t∆∞·ªùng l·ª≠a g·ª≠i l·ªánh t·ª´ ch·ªëi r√µ r√†ng ·ªü c·∫•p ƒë·ªô giao th·ª©c (t·ª´ ch·ªëi/t·ª´ ch·ªëi) hay √¢m th·∫ßm lo·∫°i b·ªè (lo·∫°i b·ªè).
Nhi·ªÅu giao di·ªán ng∆∞·ªùi d√πng t∆∞·ªùng l·ª≠a cung c·∫•p c·∫£ hai t√πy ch·ªçn; h√£y ki·ªÉm tra ph·∫£n h·ªìi ƒë∆∞·ª£c tr·∫£ v·ªÅ (ICMP, TCP RST, kh√¥ng c√≥ g√¨) ƒë·ªÉ hi·ªÉu ch√≠nh x√°c h√†nh vi.
B·∫£n t√≥m t·∫Øt

T·ª´ ch·ªëi = t·ª´ ch·ªëi r√µ r√†ng; ph·∫£n h·ªìi ngay l·∫≠p t·ª©c cho ng∆∞·ªùi g·ª≠i (x·ª≠ l√Ω nhanh h∆°n, √≠t l√©n l√∫t h∆°n).
Drop = lo·∫°i b·ªè √¢m th·∫ßm; kh√¥ng ph·∫£n h·ªìi (t√†ng h√¨nh h∆°n, l·ªói ch·∫≠m h∆°n). L·ª±a ch·ªçn d·ª±a tr√™n nhu c·∫ßu v·∫≠n h√†nh, ch·∫©n ƒëo√°n v√† t√¨nh h√¨nh b·∫£o m·∫≠t.

==> Hi·ªán t·∫°i ƒë√£ ch·∫°y ƒë∆∞·ª£c code train c∆° b·∫£n, ra accuracy √† 1.00 (kh·∫£ nƒÉng cao ƒëang b·ªã overfit). Ti·∫øp theo c·∫ßn th·ª≠ v·ªõi c√°c thu·∫≠t to√°n kh√°c, tinh ch·ªânh hyperparameter, v√† th√™m d·ªØ li·ªáu ƒë·ªÉ c·∫£i thi·ªán m√¥ h√¨nh.

=========================
|| 23/10/2025 (tuandat):
=========================
- ƒê·ªïi t√™n ml_model.py th√†nh 1_Data_cleaning.py
- ƒê·ªïi t√™n train_ml.py th√†nh 2_Data_analysis.py
- ƒê·ªïi t√™n test_predict.py th√†nh

=========================
|| 24/10/2025 (tuandat):
=========================
1Ô∏è‚É£ hidden_layer_sizes
```
clf__hidden_layer_sizes=(500, 250, 125, 62)
```
- ƒê√¢y l√† c·∫•u tr√∫c m·∫°ng n∆°-ron ·∫©n: s·ªë l∆∞·ª£ng n∆°-ron ·ªü m·ªói layer ·∫©n.
    - V√≠ d·ª• (500, 250, 125, 62) c√≥ 4 layer ·∫©n, l·∫ßn l∆∞·ª£t 500, 250, 125, 62 n∆°-ron.
- ·∫¢nh h∆∞·ªüng:
    - Nhi·ªÅu n∆°-ron/layer ‚Üí m√¥ h√¨nh m·∫°nh h∆°n, h·ªçc d·ªØ li·ªáu ph·ª©c t·∫°p t·ªët h∆°n.
    - Nh∆∞ng qu√° nhi·ªÅu ‚Üí d·ªÖ overfitting v√† t·ªën th·ªùi gian hu·∫•n luy·ªán.

2Ô∏è‚É£ alpha
```
clf__alpha = 0.0005, 0.001, 0.01, 0.1, 1
```
- Regularization term (L2 penalty) ƒë·ªÉ tr√°nh overfitting.
- ·∫¢nh h∆∞·ªüng:
    - Nh·ªè ‚Üí m√¥ h√¨nh c√≥ th·ªÉ h·ªçc qu√° m·ª©c d·ªØ li·ªáu hu·∫•n luy·ªán (overfit).
    - L·ªõn ‚Üí m√¥ h√¨nh ƒë∆°n gi·∫£n h∆°n, c√≥ th·ªÉ underfit n·∫øu qu√° cao.

3Ô∏è‚É£ learning_rate
```
clf__learning_rate = ['constant', 'invscaling']
```
- Quy ƒë·ªãnh c√°ch learning rate thay ƒë·ªïi trong qu√° tr√¨nh hu·∫•n luy·ªán.
    - 'constant' ‚Üí learning rate gi·ªØ nguy√™n.
    - 'invscaling' ‚Üí gi·∫£m theo s·ªë epoch (eta = eta0 / t^power).
- ·∫¢nh h∆∞·ªüng:
    - Gi·∫£m learning rate d·∫ßn ‚Üí gi√∫p m√¥ h√¨nh h·ªôi t·ª• ·ªïn ƒë·ªãnh, tr√°nh ‚Äúnh·∫£y‚Äù qua minima.

4Ô∏è‚É£ learning_rate_init
```
clf__learning_rate_init = [0.001, 0.01, 0.1, 1]
```
- Gi√° tr·ªã kh·ªüi t·∫°o learning rate (eta0).
- ·∫¢nh h∆∞·ªüng:
    - Qu√° nh·ªè ‚Üí h·ªçc r·∫•t ch·∫≠m, l√¢u h·ªôi t·ª•.
    - Qu√° l·ªõn ‚Üí model c√≥ th·ªÉ kh√¥ng h·ªôi t·ª•, ho·∫∑c loss nh·∫£y lung tung.

5Ô∏è‚É£ momentum
```
clf__momentum = [0, 0.9]
```
- Momentum gi√∫p tƒÉng t·ªëc gradient descent v√† gi·∫£m kh·∫£ nƒÉng k·∫πt t·∫°i local minima.
- ·∫¢nh h∆∞·ªüng:
    - 0 ‚Üí kh√¥ng d√πng momentum.
    - 0.9 ‚Üí model h·ªçc nhanh h∆°n v√† ·ªïn ƒë·ªãnh h∆°n.

6Ô∏è‚É£ min_df trong vectorizer
```
vect__min_df = [1, 2, 5, 10, 20, 40]
```
- Ch·ªâ gi·ªØ t·ª´ xu·∫•t hi·ªán ‚â• min_df.
- ·∫¢nh h∆∞·ªüng:
    - Nh·ªè ‚Üí nhi·ªÅu t·ª´ hi·∫øm, c√≥ th·ªÉ noise.
    - L·ªõn ‚Üí b·ªè t·ª´ hi·∫øm, gi·∫£m noise nh∆∞ng c√≥ th·ªÉ m·∫•t th√¥ng tin.

7Ô∏è‚É£ Early stopping
- Khi loss kh√¥ng gi·∫£m ƒë·ªß trong 10 epoch li√™n ti·∫øp, training d·ª´ng s·ªõm.
- Gi√∫p tr√°nh overfitting v√† ti·∫øt ki·ªám th·ªùi gian.

üí° T√≥m t·∫Øt:

hidden_layer_sizes, alpha, learning_rate, learning_rate_init, momentum ‚Üí ƒëi·ªÅu khi·ªÉn MLP h·ªçc th·∫ø n√†o.

min_df ‚Üí l√†m s·∫°ch d·ªØ li·ªáu vƒÉn b·∫£n tr∆∞·ªõc khi h·ªçc.

GridSearchCV k·∫øt h·ª£p c√°c tham s·ªë n√†y ƒë·ªÉ t√¨m b·ªô t·ªëi ∆∞u cho accuracy cao nh·∫•t.



'''

'''


C·∫ßn Ho√†n thi·ªán backend/ml_model.py loader/predict wrapper v√† t√≠ch h·ª£p v√†o backend/waf.py.

01_Data_Cleaning c≈©:
"""
1_Data_cleaning.py
------------------
Script l√†m s·∫°ch d·ªØ li·ªáu payload cho d·ª± √°n Machine Learning Web Application Firewall (WAF)

Ch·ª©c nƒÉng:
- ƒê·ªçc d·ªØ li·ªáu t·ª´ c√°c file .txt (SQL, XSS, SHELL)
- G·∫Øn nh√£n (malicious ho·∫∑c non-malicious)
- L√†m s·∫°ch d·ªØ li·ªáu: lo·∫°i b·ªè tr√πng, tr·ªëng, k√Ω t·ª± th·ª´a, payload l·ªói
- Tr·ªôn ng·∫´u nhi√™n d·ªØ li·ªáu ƒë·ªÉ tr√°nh bias
- L∆∞u k·∫øt qu·∫£ th√†nh .csv v√† .pickle ƒë·ªÉ s·ª≠ d·ª•ng trong b∆∞·ªõc ph√¢n t√≠ch
"""

# ===============================
# STEP 1: Import th∆∞ vi·ªán c·∫ßn thi·∫øt
# ===============================
import numpy as np
import pandas as pd
import pickle

# ===============================
# STEP 2: ƒê·ªãnh nghƒ©a h√†m ƒë·ªçc file .txt v√† t·∫°o DataFrame
# ===============================
def from_txt_to_dataframe(src_file, is_malicious, injection_type):
    """
    ƒê·ªçc payloads t·ª´ file txt trong th∆∞ m·ª•c 'data/'
    v√† t·∫°o th√†nh DataFrame g·ªìm:
    - payload: chu·ªói d·ªØ li·ªáu
    - is_malicious: 1 n·∫øu l√† d·ªØ li·ªáu t·∫•n c√¥ng, 0 n·∫øu h·ª£p l·ªá
    - injection_type: lo·∫°i t·∫•n c√¥ng (SQL, XSS, SHELL, LEGAL)
    """
    path = f"data/{src_file}.txt"
    with open(path, "r", encoding="utf-8") as f:
        payloads_txt = f.readlines()

    # T·∫°o DataFrame t·ª´ danh s√°ch payloads
    payloads = pd.DataFrame(payloads_txt, columns=["payload"])
    payloads["is_malicious"] = [is_malicious] * len(payloads)
    payloads["injection_type"] = [injection_type] * len(payloads)

    print(f"[INFO] Loaded {len(payloads)} payloads from {src_file}.txt ({injection_type})")
    print(payloads.head(), "\n")
    return payloads


# ===============================
# STEP 3: G·ªôp t·∫•t c·∫£ payloads v√†o 1 DataFrame
# ===============================
payloads = pd.DataFrame(columns=["payload", "is_malicious", "injection_type"])

payloads = pd.concat([
    from_txt_to_dataframe("SQLCollection", 1, "SQL"),
    from_txt_to_dataframe("XSSCollection", 1, "XSS"),
    from_txt_to_dataframe("ShellCollection", 1, "SHELL"),
    from_txt_to_dataframe("non-maliciousCollection", 0, "LEGAL")
], ignore_index=True)

print(f"[INFO] T·ªïng s·ªë d√≤ng ban ƒë·∫ßu: {len(payloads)}\n")

# ===============================
# STEP 4: L√†m s·∫°ch d·ªØ li·ªáu
# ===============================

# 4.1. X√≥a k√Ω t·ª± xu·ªëng d√≤ng '\n' v√† kho·∫£ng tr·∫Øng d∆∞ th·ª´a
payloads["payload"] = payloads["payload"].str.strip("\n")
payloads["payload"] = payloads["payload"].str.strip()

# 4.2. Lo·∫°i b·ªè d√≤ng tr·ªëng
rows_before = len(payloads)
payloads = payloads[payloads["payload"].str.len() != 0]
print(f"[CLEAN] Empty payloads removed: {rows_before - len(payloads)}")

# 4.3. Lo·∫°i b·ªè payload t·∫•n c√¥ng c√≥ ƒë·ªô d√†i = 1 k√Ω t·ª±
rows_before = len(payloads)
payloads = payloads[
    (payloads["is_malicious"] == 0) |
    ((payloads["is_malicious"] == 1) & (payloads["payload"].str.len() > 1))
]
print(f"[CLEAN] Malicious payloads of length 1 removed: {rows_before - len(payloads)}")

# 4.4. Lo·∫°i b·ªè d√≤ng tr√πng l·∫∑p
rows_before = len(payloads)
payloads = payloads.drop_duplicates(subset="payload", keep="last")
print(f"[CLEAN] Duplicate payloads removed: {rows_before - len(payloads)}")

# 4.5. X·ª≠ l√Ω c√°c payload c√≥ ƒë·ªãnh d·∫°ng byte (b'<payload>') ‚Üí chuy·ªÉn th√†nh chu·ªói b√¨nh th∆∞·ªùng
payloads["payload"] = [
    p[2:-1] if p.startswith("b'") or p.startswith('b"') else p
    for p in payloads["payload"]
]

# ===============================
# STEP 5: Shuffle d·ªØ li·ªáu v√† reset index
# ===============================
payloads = payloads.sample(frac=1).reset_index(drop=True)
payloads.index.name = "index"

# ===============================
# STEP 6: L∆∞u d·ªØ li·ªáu ra file CSV
# ===============================
payloads.to_csv("data/payloads.csv", encoding="utf-8")
print(f"[SAVE] D·ªØ li·ªáu ƒë√£ l∆∞u v√†o data/payloads.csv ({len(payloads)} d√≤ng)")

# ===============================
# STEP 7: Ki·ªÉm tra v√† lo·∫°i b·ªè gi√° tr·ªã null sau khi l∆∞u CSV
# ===============================
payloads = pd.read_csv("data/raw/payloads.csv", index_col="index", encoding="utf-8")
rows_before = len(payloads)
payloads = payloads[~payloads["payload"].isnull()]
print(f"[CLEAN] Null/NaN payloads removed: {rows_before - len(payloads)}")

# L∆∞u l·∫°i file CSV sau khi lo·∫°i null
payloads.to_csv("data/payloads.csv", encoding="utf-8")

# ===============================
# STEP 8: (Tu·ª≥ ch·ªçn) L∆∞u DataFrame th√†nh file .pickle ƒë·ªÉ load nhanh sau n√†y
# ===============================
with open("data/payloads.pkl", "wb") as f:
    pickle.dump(payloads, f)
print("[SAVE] DataFrame ƒë√£ l∆∞u v√†o data/payloads.pkl")

print("\n[INFO] Data cleaning ho√†n t·∫•t.")
print(f"T·ªïng s·ªë payloads cu·ªëi c√πng: {len(payloads)}")
print(payloads.head())


SQL Injection Dataset:
1. https://github.com/grananqvist/Machine-Learning-Web-Application-Firewall-and-Dataset/tree/master/data
2. https://www.kaggle.com/datasets/syedsaqlainhussain/sql-injection-dataset/data
3. https://github.com/chouaibcher/WAF-AI/blob/main/data/raw/SQLpayloads.txt

XSS Dataset:
1. https://www.kaggle.com/datasets/syedsaqlainhussain/cross-site-scripting-xss-dataset-for-deep-learning
2. https://github.com/grananqvist/Machine-Learning-Web-Application-Firewall-and-Dataset/tree/master/data

All Dataset:
1. https://github.com/foospidy/payloads/tree/master